{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3719120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "409fe41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Base_M43_Pratique_CREDIT_CARD_FRAUD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bfd6dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d18da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "933bc627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.175161e-15</td>\n",
       "      <td>3.384974e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.094852e-15</td>\n",
       "      <td>1.021879e-15</td>\n",
       "      <td>1.494498e-15</td>\n",
       "      <td>-5.620335e-16</td>\n",
       "      <td>1.149614e-16</td>\n",
       "      <td>-2.414189e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.628620e-16</td>\n",
       "      <td>-3.576577e-16</td>\n",
       "      <td>2.618565e-16</td>\n",
       "      <td>4.473914e-15</td>\n",
       "      <td>5.109395e-16</td>\n",
       "      <td>1.686100e-15</td>\n",
       "      <td>-3.661401e-16</td>\n",
       "      <td>-1.227452e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.175161e-15  3.384974e-16 -1.379537e-15  2.094852e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   1.021879e-15  1.494498e-15 -5.620335e-16  1.149614e-16 -2.414189e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.628620e-16 -3.576577e-16  2.618565e-16  4.473914e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.109395e-16  1.686100e-15 -3.661401e-16 -1.227452e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "210cb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DATASET JA ESTRUTURADO, ENTÃO NÃO HÁ NECESSIDADE DE TRATAMENTO DE DADOS ####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b488269",
   "metadata": {},
   "source": [
    "#### Criação de FEATURES ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "137e74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.unique of 0          Muito Alto\n",
      "1         Muito Baixo\n",
      "2          Muito Alto\n",
      "3          Muito Alto\n",
      "4                Alto\n",
      "             ...     \n",
      "284802    Muito Baixo\n",
      "284803          Médio\n",
      "284804           Alto\n",
      "284805          Baixo\n",
      "284806     Muito Alto\n",
      "Name: Amount_Faixas, Length: 284807, dtype: category\n",
      "Categories (5, object): ['Muito Baixo' < 'Baixo' < 'Médio' < 'Alto' < 'Muito Alto']>\n"
     ]
    }
   ],
   "source": [
    "df[\"Amount_Faixas\"] = pd.qcut(df[\"Amount\"], 5, labels=[\"Muito Baixo\",\"Baixo\", \"Médio\", \"Alto\", \"Muito Alto\"])\n",
    "print(df[\"Amount_Faixas\"].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fd95590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time\n",
      "163152.0    36\n",
      "64947.0     26\n",
      "68780.0     25\n",
      "3767.0      21\n",
      "3770.0      20\n",
      "            ..\n",
      "172760.0     1\n",
      "172758.0     1\n",
      "172757.0     1\n",
      "172756.0     1\n",
      "172754.0     1\n",
      "Name: count, Length: 124592, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Time\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e81b9927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiag\\AppData\\Local\\Temp\\ipykernel_15860\\2338059509.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  fraude_rate = (df.groupby(\"Amount_Faixas\")[\"Class\"].mean())\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraude_rate = (df.groupby(\"Amount_Faixas\")[\"Class\"].mean())\n",
    "\n",
    "plt.figure()\n",
    "fraude_rate.plot(kind=\"bar\")\n",
    "\n",
    "plt.title(\"Taxa de fraude por faixa de valor\")\n",
    "plt.xlabel(\"Faixa de Amount\")\n",
    "plt.ylabel(\"Proporção de fraude\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17c86db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class    1.000000\n",
       "V17      0.326481\n",
       "V14      0.302544\n",
       "V12      0.260593\n",
       "V10      0.216883\n",
       "V16      0.196539\n",
       "V3       0.192961\n",
       "V7       0.187257\n",
       "V11      0.154876\n",
       "V4       0.133447\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = df.corr(numeric_only=True)[\"Class\"].abs().sort_values(ascending=False)\n",
    "corr.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d38e4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Criando interações das 5 variaveis com maior correlação com a variável alvo 'Class' ###\n",
    "corr = df.corr(numeric_only=True)[\"Class\"].abs().sort_values(ascending=False)    \n",
    "top_features = corr.drop(\"Amount\").head(5).index\n",
    "for feature in top_features:\n",
    "    df[f\"{feature}_x_Amount\"] = df[feature] * df[\"Amount\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0aa79be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount_Faixas</th>\n",
       "      <th>Class_x_Amount</th>\n",
       "      <th>V17_x_Amount</th>\n",
       "      <th>V14_x_Amount</th>\n",
       "      <th>V12_x_Amount</th>\n",
       "      <th>V10_x_Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.116657</td>\n",
       "      <td>-46.557159</td>\n",
       "      <td>-92.435364</td>\n",
       "      <td>13.584624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Baixo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.308825</td>\n",
       "      <td>-0.386747</td>\n",
       "      <td>2.865483</td>\n",
       "      <td>-0.449161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420.301005</td>\n",
       "      <td>-62.837083</td>\n",
       "      <td>25.023248</td>\n",
       "      <td>78.626047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.485459</td>\n",
       "      <td>-35.558583</td>\n",
       "      <td>22.011186</td>\n",
       "      <td>-6.786562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.589956</td>\n",
       "      <td>-78.365692</td>\n",
       "      <td>37.668307</td>\n",
       "      <td>52.707679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V27       V28  Amount  Class  Amount_Faixas  \\\n",
       "0  0.098698  0.363787  ...  0.133558 -0.021053  149.62      0     Muito Alto   \n",
       "1  0.085102 -0.255425  ... -0.008983  0.014724    2.69      0    Muito Baixo   \n",
       "2  0.247676 -1.514654  ... -0.055353 -0.059752  378.66      0     Muito Alto   \n",
       "3  0.377436 -1.387024  ...  0.062723  0.061458  123.50      0     Muito Alto   \n",
       "4 -0.270533  0.817739  ...  0.219422  0.215153   69.99      0           Alto   \n",
       "\n",
       "   Class_x_Amount  V17_x_Amount  V14_x_Amount  V12_x_Amount  V10_x_Amount  \n",
       "0             0.0     31.116657    -46.557159    -92.435364     13.584624  \n",
       "1             0.0     -0.308825     -0.386747      2.865483     -0.449161  \n",
       "2             0.0    420.301005    -62.837083     25.023248     78.626047  \n",
       "3             0.0    -84.485459    -35.558583     22.011186     -6.786562  \n",
       "4             0.0    -16.589956    -78.365692     37.668307     52.707679  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1941bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['Class_x_Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f837f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### elevar o valor absoluto das colunas PCA ao quadrado e somar para obter a norma, visando visualizar componentes e comportamentos mais importantes; quanto maior, mais estranho a transação ###\n",
    "pca_cols = [f\"V{i}\" for i in range(1, 29)]\n",
    "df[\"PCA_norm\"] = (df[pca_cols]**2).sum(axis=1)**0.5 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95532791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### contar o número de componentes PCA com valor absoluto maior que 2 ###\n",
    "df[\"PCA_extreme_count\"] = (df[pca_cols].abs() > 2).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a715559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>Amount_Faixas</th>\n",
       "      <th>Class_x_Amount</th>\n",
       "      <th>V17_x_Amount</th>\n",
       "      <th>V14_x_Amount</th>\n",
       "      <th>V12_x_Amount</th>\n",
       "      <th>V10_x_Amount</th>\n",
       "      <th>PCA_norm</th>\n",
       "      <th>PCA_extreme_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.116657</td>\n",
       "      <td>-46.557159</td>\n",
       "      <td>-92.435364</td>\n",
       "      <td>13.584624</td>\n",
       "      <td>3.911559</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Baixo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.308825</td>\n",
       "      <td>-0.386747</td>\n",
       "      <td>2.865483</td>\n",
       "      <td>-0.449161</td>\n",
       "      <td>2.674524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420.301005</td>\n",
       "      <td>-62.837083</td>\n",
       "      <td>25.023248</td>\n",
       "      <td>78.626047</td>\n",
       "      <td>6.080512</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "      <td>Muito Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-84.485459</td>\n",
       "      <td>-35.558583</td>\n",
       "      <td>22.011186</td>\n",
       "      <td>-6.786562</td>\n",
       "      <td>4.284356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "      <td>Alto</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.589956</td>\n",
       "      <td>-78.365692</td>\n",
       "      <td>37.668307</td>\n",
       "      <td>52.707679</td>\n",
       "      <td>3.565131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...  Amount  Class  Amount_Faixas  Class_x_Amount  \\\n",
       "0  0.098698  0.363787  ...  149.62      0     Muito Alto             0.0   \n",
       "1  0.085102 -0.255425  ...    2.69      0    Muito Baixo             0.0   \n",
       "2  0.247676 -1.514654  ...  378.66      0     Muito Alto             0.0   \n",
       "3  0.377436 -1.387024  ...  123.50      0     Muito Alto             0.0   \n",
       "4 -0.270533  0.817739  ...   69.99      0           Alto             0.0   \n",
       "\n",
       "   V17_x_Amount  V14_x_Amount  V12_x_Amount  V10_x_Amount  PCA_norm  \\\n",
       "0     31.116657    -46.557159    -92.435364     13.584624  3.911559   \n",
       "1     -0.308825     -0.386747      2.865483     -0.449161  2.674524   \n",
       "2    420.301005    -62.837083     25.023248     78.626047  6.080512   \n",
       "3    -84.485459    -35.558583     22.011186     -6.786562  4.284356   \n",
       "4    -16.589956    -78.365692     37.668307     52.707679  3.565131   \n",
       "\n",
       "   PCA_extreme_count  \n",
       "0                  1  \n",
       "1                  0  \n",
       "2                  3  \n",
       "3                  0  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4da8f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Analisando a taxa de fraude em relação ao número de componentes PCA extremos ###\n",
    "fraud_rate = (df.groupby(\"PCA_extreme_count\")[\"Class\"].mean())\n",
    "plt.figure()\n",
    "fraud_rate.plot(kind=\"bar\")\n",
    "plt.xlabel(\"PCA_extreme_count\")\n",
    "plt.ylabel(\"Taxa de fraude\")\n",
    "plt.title(\"Taxa de fraude/probabilidade por número de extremos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2650c2",
   "metadata": {},
   "source": [
    "### Grafico claramente aponta uma maior ocorrência de fraudes onde nas transações há uma maior ocorrencia de extrem counts (valores 'outliers' nas variaveis PCAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75bb4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=[\"Amount_Faixas\"],\n",
    "    drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4ef8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Seperando treino e teste ###\n",
    "X = df.drop(columns=[\"Class\"])\n",
    "y = df[\"Class\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # stratify mantém a proporção de classes na divisão treino/teste ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7dfbbd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 0.001727485630620034\n",
      "Treino: 0.001729245759178389\n",
      "Teste: 0.0017204452090867595\n"
     ]
    }
   ],
   "source": [
    "print(\"Total:\", y.mean())\n",
    "print(\"Treino:\", y_train.mean())\n",
    "print(\"Teste:\", y_test.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb7b04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = [\"Amount\", \"V17_x_Amount\", \"V14_x_Amount\", \"V12_x_Amount\", \"V10_x_Amount\"]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Copiamos para evitar modificar os dados originais\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Fit APENAS no treino\n",
    "X_train_scaled[scale_cols] = scaler.fit_transform(X_train[scale_cols])\n",
    "\n",
    "# Transform no teste usando parâmetros do treino\n",
    "X_test_scaled[scale_cols] = scaler.transform(X_test[scale_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6535e3cd",
   "metadata": {},
   "source": [
    "### Treinando modelo de Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd0842f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thiag\\EBAC\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-4.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('penalty',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=penalty,-%7B%27l1%27%2C%20%27l2%27%2C%20%27elasticnet%27%2C%20None%7D%2C%20default%3D%27l2%27\">\n",
       "            penalty\n",
       "            <span class=\"param-doc-description\">penalty: {'l1', 'l2', 'elasticnet', None}, default='l2'<br><br>Specify the norm of the penalty:<br><br>- `None`: no penalty is added;<br>- `'l2'`: add a L2 penalty term and it is the default choice;<br>- `'l1'`: add a L1 penalty term;<br>- `'elasticnet'`: both L1 and L2 penalty terms are added.<br><br>.. warning::<br>   Some penalties may not work with some solvers. See the parameter<br>   `solver` below, to know the compatibility between the penalty and<br>   solver.<br><br>.. versionadded:: 0.19<br>   l1 penalty with SAGA solver (allowing 'multinomial' + L1)<br><br>.. deprecated:: 1.8<br>   `penalty` was deprecated in version 1.8 and will be removed in 1.10.<br>   Use `l1_ratio` instead. `l1_ratio=0` for `penalty='l2'`, `l1_ratio=1` for<br>   `penalty='l1'` and `l1_ratio` set to any float between 0 and 1 for<br>   `'penalty='elasticnet'`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;deprecated&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('C',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=C,-float%2C%20default%3D1.0\">\n",
       "            C\n",
       "            <span class=\"param-doc-description\">C: float, default=1.0<br><br>Inverse of regularization strength; must be a positive float.<br>Like in support vector machines, smaller values specify stronger<br>regularization. `C=np.inf` results in unpenalized logistic regression.<br>For a visual example on the effect of tuning the `C` parameter<br>with an L1 penalty, see:<br>:ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('l1_ratio',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=l1_ratio,-float%2C%20default%3D0.0\">\n",
       "            l1_ratio\n",
       "            <span class=\"param-doc-description\">l1_ratio: float, default=0.0<br><br>The Elastic-Net mixing parameter, with `0 <= l1_ratio <= 1`. Setting<br>`l1_ratio=1` gives a pure L1-penalty, setting `l1_ratio=0` a pure L2-penalty.<br>Any value between 0 and 1 gives an Elastic-Net penalty of the form<br>`l1_ratio * L1 + (1 - l1_ratio) * L2`.<br><br>.. warning::<br>   Certain values of `l1_ratio`, i.e. some penalties, may not work with some<br>   solvers. See the parameter `solver` below, to know the compatibility between<br>   the penalty and solver.<br><br>.. versionchanged:: 1.8<br>    Default value changed from None to 0.0.<br><br>.. deprecated:: 1.8<br>    `None` is deprecated and will be removed in version 1.10. Always use<br>    `l1_ratio` to specify the penalty type.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('dual',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=dual,-bool%2C%20default%3DFalse\">\n",
       "            dual\n",
       "            <span class=\"param-doc-description\">dual: bool, default=False<br><br>Dual (constrained) or primal (regularized, see also<br>:ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation<br>is only implemented for l2 penalty with liblinear solver. Prefer `dual=False`<br>when n_samples > n_features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=tol,-float%2C%20default%3D1e-4\">\n",
       "            tol\n",
       "            <span class=\"param-doc-description\">tol: float, default=1e-4<br><br>Tolerance for stopping criteria.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=fit_intercept,-bool%2C%20default%3DTrue\">\n",
       "            fit_intercept\n",
       "            <span class=\"param-doc-description\">fit_intercept: bool, default=True<br><br>Specifies if a constant (a.k.a. bias or intercept) should be<br>added to the decision function.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('intercept_scaling',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=intercept_scaling,-float%2C%20default%3D1\">\n",
       "            intercept_scaling\n",
       "            <span class=\"param-doc-description\">intercept_scaling: float, default=1<br><br>Useful only when the solver `liblinear` is used<br>and `self.fit_intercept` is set to `True`. In this case, `x` becomes<br>`[x, self.intercept_scaling]`,<br>i.e. a \"synthetic\" feature with constant value equal to<br>`intercept_scaling` is appended to the instance vector.<br>The intercept becomes<br>``intercept_scaling * synthetic_feature_weight``.<br><br>.. note::<br>    The synthetic feature weight is subject to L1 or L2<br>    regularization as all other features.<br>    To lessen the effect of regularization on synthetic feature weight<br>    (and therefore on the intercept) `intercept_scaling` has to be increased.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=class_weight,-dict%20or%20%27balanced%27%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict or 'balanced', default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one.<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.<br><br>.. versionadded:: 0.17<br>   *class_weight='balanced'*</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;balanced&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=random_state,-int%2C%20RandomState%20instance%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance, default=None<br><br>Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the<br>data. See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('solver',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=solver,-%7B%27lbfgs%27%2C%20%27liblinear%27%2C%20%27newton-cg%27%2C%20%27newton-cholesky%27%2C%20%27sag%27%2C%20%27saga%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27lbfgs%27\">\n",
       "            solver\n",
       "            <span class=\"param-doc-description\">solver: {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'<br><br>Algorithm to use in the optimization problem. Default is 'lbfgs'.<br>To choose a solver, you might want to consider the following aspects:<br><br>- 'lbfgs' is a good default solver because it works reasonably well for a wide<br>  class of problems.<br>- For :term:`multiclass` problems (`n_classes >= 3`), all solvers except<br>  'liblinear' minimize the full multinomial loss, 'liblinear' will raise an<br>  error.<br>- 'newton-cholesky' is a good choice for<br>  `n_samples` >> `n_features * n_classes`, especially with one-hot encoded<br>  categorical features with rare categories. Be aware that the memory usage<br>  of this solver has a quadratic dependency on `n_features * n_classes`<br>  because it explicitly computes the full Hessian matrix.<br>- For small datasets, 'liblinear' is a good choice, whereas 'sag'<br>  and 'saga' are faster for large ones;<br>- 'liblinear' can only handle binary classification by default. To apply a<br>  one-versus-rest scheme for the multiclass setting one can wrap it with the<br>  :class:`~sklearn.multiclass.OneVsRestClassifier`.<br><br>.. warning::<br>   The choice of the algorithm depends on the penalty chosen (`l1_ratio=0`<br>   for L2-penalty, `l1_ratio=1` for L1-penalty and `0 < l1_ratio < 1` for<br>   Elastic-Net) and on (multinomial) multiclass support:<br><br>   ================= ======================== ======================<br>   solver            l1_ratio                 multinomial multiclass<br>   ================= ======================== ======================<br>   'lbfgs'           l1_ratio=0               yes<br>   'liblinear'       l1_ratio=1 or l1_ratio=0 no<br>   'newton-cg'       l1_ratio=0               yes<br>   'newton-cholesky' l1_ratio=0               yes<br>   'sag'             l1_ratio=0               yes<br>   'saga'            0<=l1_ratio<=1           yes<br>   ================= ======================== ======================<br><br>.. note::<br>   'sag' and 'saga' fast convergence is only guaranteed on features<br>   with approximately the same scale. You can preprocess the data with<br>   a scaler from :mod:`sklearn.preprocessing`.<br><br>.. seealso::<br>   Refer to the :ref:`User Guide <Logistic_regression>` for more<br>   information regarding :class:`LogisticRegression` and more specifically the<br>   :ref:`Table <logistic_regression_solvers>`<br>   summarizing solver/penalty supports.<br><br>.. versionadded:: 0.17<br>   Stochastic Average Gradient (SAG) descent solver. Multinomial support in<br>   version 0.18.<br>.. versionadded:: 0.19<br>   SAGA solver.<br>.. versionchanged:: 0.22<br>   The default solver changed from 'liblinear' to 'lbfgs' in 0.22.<br>.. versionadded:: 1.2<br>   newton-cholesky solver. Multinomial support in version 1.6.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;lbfgs&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=max_iter,-int%2C%20default%3D100\">\n",
       "            max_iter\n",
       "            <span class=\"param-doc-description\">max_iter: int, default=100<br><br>Maximum number of iterations taken for the solvers to converge.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>For the liblinear and lbfgs solvers set verbose to any positive<br>number for verbosity.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to True, reuse the solution of the previous call to fit as<br>initialization, otherwise, just erase the previous solution.<br>Useless for liblinear solver. See :term:`the Glossary <warm_start>`.<br><br>.. versionadded:: 0.17<br>   *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.linear_model.LogisticRegression.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>Does not have any effect.<br><br>.. deprecated:: 1.8<br>   `n_jobs` is deprecated in version 1.8 and will be removed in 1.10.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-4');</script></body>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "regressao = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    random_state=42)\n",
    "\n",
    "regressao.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "933c3597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Nao-fraude       1.00      0.88      0.94     56864\n",
      "      Fraude       0.01      1.00      0.03        98\n",
      "\n",
      "    accuracy                           0.88     56962\n",
      "   macro avg       0.51      0.94      0.48     56962\n",
      "weighted avg       1.00      0.88      0.93     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_proba = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Nao-fraude\", \"Fraude\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fcd43a",
   "metadata": {},
   "source": [
    "### O modelo tem alto recall para fraudes (bom para detectar todas as fraudes), mas  precisão horrivel de 0.01 (muitos alertas falsos/'precision'),apotando diversos operações legitimas como fraude, gerando alto impacto financeiro. Um modelo seguro para fraudes mas que avisa muitos falsos positivos, por isso do precison tao baixo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c3253ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.9999592655013609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b468b81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold escolhido: 0.9999999955712047\n",
      "Precision: 0.9038461538461539\n",
      "Recall: 0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "### Aumentando a probabilidade de detectar fraudes ###\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "\n",
    "target_recall = 0.95\n",
    "\n",
    "valid_idxs = np.where(recall >= target_recall)[0]\n",
    "best_idx = valid_idxs[-1]\n",
    "\n",
    "threshold = thresholds[best_idx]\n",
    "\n",
    "print(\"Threshold escolhido:\", threshold)\n",
    "print(\"Precision:\", precision[best_idx])\n",
    "print(\"Recall:\", recall[best_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ec23133a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.90      0.96      0.93        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.95      0.98      0.97     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc53bbc",
   "metadata": {},
   "source": [
    "### Todas não fraudes classificadas certos, provavelmente mais devido a raridade de ocorrências do que da assertividade do modelo; porem modelo com esse threshold probabilistico é bem assertivo na detecção das operações que são fraudulentas, trazendo um recall ainda melhor para as operações que são fraudes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(len(y_train) - y_train.sum()) / y_train.sum(),\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "abfad464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold XGB: 0.9997924\n",
      "Precision XGB: 1.0\n",
      "Recall XGB: 0.9591836734693877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "precision_xgb, recall_xgb, thresholds_xgb = precision_recall_curve(y_test, y_proba_xgb)\n",
    "\n",
    "target_recall = 0.95\n",
    "\n",
    "valid_idxs = np.where(recall_xgb[:-1] >= target_recall)[0]\n",
    "best_idx = valid_idxs[-1]\n",
    "\n",
    "threshold_xgb = thresholds_xgb[best_idx]\n",
    "\n",
    "print(\"Threshold XGB:\", threshold_xgb)\n",
    "print(\"Precision XGB:\", precision_xgb[best_idx])\n",
    "print(\"Recall XGB:\", recall_xgb[best_idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4d2fa",
   "metadata": {},
   "source": [
    "### Valores bem parecidos com o modelo de regressão logistica, porem com o xgboost sendo mais preciso nos casos de fraudes reais. Porem pela complexidade e risco de overfitting, talvez seja mais valido optar pelo modelo mais simples de regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "38cb7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temporal = df.copy()\n",
    "df_temporal = df_temporal.sort_values(\"Time\").reset_index(drop=True)\n",
    "split_time = df_temporal[\"Time\"].quantile(0.7)\n",
    "\n",
    "train_df_t = df_temporal[df_temporal[\"Time\"] <= split_time]\n",
    "test_df_t  = df_temporal[df_temporal[\"Time\"] > split_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7b23acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = train_df_t.drop(columns=[\"Class\"])\n",
    "y_train_t = train_df_t[\"Class\"]\n",
    "\n",
    "X_test_t = test_df_t.drop(columns=[\"Class\"])\n",
    "y_test_t = test_df_t[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3450d89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t[scale_cols] = scaler.fit_transform(X_train_t[scale_cols])\n",
    "X_test_t[scale_cols]  = scaler.transform(X_test_t[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "72bcd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xgb_model_t = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=(len(y_train_t) - y_train_t.sum()) / y_train_t.sum(),\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model_t.fit(X_train_t, y_train_t)\n",
    "y_proba_xgb = xgb_model_t.predict_proba(X_test_t)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "164fa870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold XGB: 0.0044197296\n",
      "Precision XGB: 1.0\n",
      "Recall XGB: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "precision_xgb, recall_xgb, thresholds_xgb = precision_recall_curve(y_test_t, y_proba_xgb)\n",
    "\n",
    "target_recall = 0.95\n",
    "\n",
    "valid_idxs = np.where(recall_xgb[:-1] >= target_recall)[0]\n",
    "best_idx = valid_idxs[-1]\n",
    "\n",
    "threshold_xgb = thresholds_xgb[best_idx]\n",
    "\n",
    "print(\"Threshold XGB:\", threshold_xgb)\n",
    "print(\"Precision XGB:\", precision_xgb[best_idx])\n",
    "print(\"Recall XGB:\", recall_xgb[best_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10464279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85331     0]\n",
      " [    4   104]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_t, (y_proba_xgb >= threshold_xgb).astype(int))\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d4021",
   "metadata": {},
   "source": [
    "### Mesmo com split temporal o modelo segue muito assertivo!  Nenhuma transação legitima, das 8533, foi bloqueada; e somente 4 fraudelentas passaram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf052e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
